{% set version = "1.7.0" %}
{% set number = 3 %}
# see github.com/conda-forge/conda-forge.github.io/issues/1059 for naming discussion
{% set faiss_proc_type = "cuda" if cuda_compiler_version != "None" else "cpu" %}

# headers for upstream-folders 'faiss/*.h', 'faiss/{impl,invlists,utils}/*.h',
# see https://github.com/facebookresearch/faiss/blob/v{{ version }}/faiss/CMakeLists.txt;
# gpu adds headers in 'faiss/gpu/*.h', 'faiss/gpu/{impl,utils}/*.(cu)?h'.
# generated by:
# ls faiss/{.,impl,invlists,utils} | grep -E "h$"
# ls faiss/gpu/{.,impl,utils,utils/blockselect,utils/warpselect} | grep -E "h$"
{% set headers = [
    'AutoTune.h', 'Clustering.h', 'IVFlib.h', 'Index.h', 'Index2Layer.h', 'IndexBinary.h',
    'IndexBinaryFlat.h', 'IndexBinaryFromFloat.h', 'IndexBinaryHNSW.h', 'IndexBinaryHash.h',
    'IndexBinaryIVF.h', 'IndexFlat.h', 'IndexHNSW.h', 'IndexIVF.h', 'IndexIVFFlat.h',
    'IndexIVFPQ.h', 'IndexIVFPQFastScan.h', 'IndexIVFPQR.h', 'IndexIVFSpectralHash.h',
    'IndexLSH.h', 'IndexLattice.h', 'IndexPQ.h', 'IndexPQFastScan.h', 'IndexPreTransform.h',
    'IndexRefine.h', 'IndexReplicas.h', 'IndexScalarQuantizer.h', 'IndexShards.h', 'MatrixStats.h',
    'MetaIndexes.h', 'MetricType.h', 'VectorTransform.h', 'clone_index.h', 'index_factory.h',
    'index_io.h',
    'impl/AuxIndexStructures.h', 'impl/FaissAssert.h', 'impl/FaissException.h', 'impl/HNSW.h',
    'impl/PolysemousTraining.h', 'impl/ProductQuantizer-inl.h', 'impl/ProductQuantizer.h',
    'impl/ResultHandler.h', 'impl/ScalarQuantizer.h', 'impl/ThreadedIndex-inl.h',
    'impl/ThreadedIndex.h', 'impl/io.h', 'impl/io_macros.h', 'impl/lattice_Zn.h',
    'impl/platform_macros.h', 'impl/pq4_fast_scan.h', 'impl/simd_result_handlers.h',
    'invlists/BlockInvertedLists.h', 'invlists/DirectMap.h', 'invlists/InvertedLists.h',
    'invlists/InvertedListsIOHook.h',
    'utils/AlignedTable.h', 'utils/Heap.h', 'utils/WorkerThread.h', 'utils/distances.h',
    'utils/extra_distances.h', 'utils/hamming-inl.h', 'utils/hamming.h',
    'utils/ordered_key_value.h', 'utils/partitioning.h', 'utils/quantize_lut.h', 'utils/random.h',
    'utils/simdlib.h', 'utils/simdlib_avx2.h', 'utils/simdlib_emulated.h', 'utils/utils.h'
] + (not win) * [
    'invlists/OnDiskInvertedLists.h'
] + (cuda_compiler_version != "None") * [
    'gpu/GpuAutoTune.h', 'gpu/GpuCloner.h', 'gpu/GpuClonerOptions.h', 'gpu/GpuDistance.h',
    'gpu/GpuFaissAssert.h', 'gpu/GpuIndex.h', 'gpu/GpuIndexBinaryFlat.h', 'gpu/GpuIndexFlat.h',
    'gpu/GpuIndexIVF.h', 'gpu/GpuIndexIVFFlat.h', 'gpu/GpuIndexIVFPQ.h',
    'gpu/GpuIndexIVFScalarQuantizer.h', 'gpu/GpuIndicesOptions.h', 'gpu/GpuResources.h',
    'gpu/StandardGpuResources.h',
    'gpu/impl/BinaryDistance.cuh', 'gpu/impl/BinaryFlatIndex.cuh', 'gpu/impl/BroadcastSum.cuh',
    'gpu/impl/Distance.cuh', 'gpu/impl/DistanceUtils.cuh', 'gpu/impl/FlatIndex.cuh',
    'gpu/impl/GeneralDistance.cuh', 'gpu/impl/GpuScalarQuantizer.cuh', 'gpu/impl/IVFAppend.cuh',
    'gpu/impl/IVFBase.cuh', 'gpu/impl/IVFFlat.cuh', 'gpu/impl/IVFFlatScan.cuh',
    'gpu/impl/IVFInterleaved.cuh', 'gpu/impl/IVFPQ.cuh', 'gpu/impl/IVFUtils.cuh',
    'gpu/impl/InterleavedCodes.h', 'gpu/impl/L2Norm.cuh', 'gpu/impl/L2Select.cuh',
    'gpu/impl/PQCodeDistances-inl.cuh', 'gpu/impl/PQCodeDistances.cuh', 'gpu/impl/PQCodeLoad.cuh',
    'gpu/impl/PQScanMultiPassNoPrecomputed-inl.cuh', 'gpu/impl/PQScanMultiPassNoPrecomputed.cuh',
    'gpu/impl/PQScanMultiPassPrecomputed.cuh', 'gpu/impl/RemapIndices.h',
    'gpu/impl/VectorResidual.cuh',
    'gpu/utils/BlockSelectKernel.cuh', 'gpu/utils/Comparators.cuh',
    'gpu/utils/ConversionOperators.cuh', 'gpu/utils/CopyUtils.cuh', 'gpu/utils/DeviceDefs.cuh',
    'gpu/utils/DeviceTensor-inl.cuh', 'gpu/utils/DeviceTensor.cuh', 'gpu/utils/DeviceUtils.h',
    'gpu/utils/DeviceVector.cuh', 'gpu/utils/Float16.cuh', 'gpu/utils/HostTensor-inl.cuh',
    'gpu/utils/HostTensor.cuh', 'gpu/utils/Limits.cuh', 'gpu/utils/LoadStoreOperators.cuh',
    'gpu/utils/MathOperators.cuh', 'gpu/utils/MatrixMult-inl.cuh', 'gpu/utils/MatrixMult.cuh',
    'gpu/utils/MergeNetworkBlock.cuh', 'gpu/utils/MergeNetworkUtils.cuh',
    'gpu/utils/MergeNetworkWarp.cuh', 'gpu/utils/NoTypeTensor.cuh', 'gpu/utils/Pair.cuh',
    'gpu/utils/PtxUtils.cuh', 'gpu/utils/ReductionOperators.cuh', 'gpu/utils/Reductions.cuh',
    'gpu/utils/Select.cuh', 'gpu/utils/StackDeviceMemory.h', 'gpu/utils/StaticUtils.h',
    'gpu/utils/Tensor-inl.cuh', 'gpu/utils/Tensor.cuh', 'gpu/utils/ThrustAllocator.cuh',
    'gpu/utils/Timer.h', 'gpu/utils/Transpose.cuh', 'gpu/utils/WarpPackedBits.cuh',
    'gpu/utils/WarpSelectKernel.cuh', 'gpu/utils/WarpShuffles.cuh',
    'gpu/utils/blockselect/BlockSelectImpl.cuh', 'gpu/utils/warpselect/WarpSelectImpl.cuh'
] %}

package:
  name: faiss-split
  version: {{ version }}

source:
  url: https://github.com/facebookresearch/faiss/archive/v{{ version }}.tar.gz
  sha256: f86d346ac9f409ee30abe37e52f6cce366b7f60d3924d65719f40aa07ceb4bec
  patches:
    - patches/0001-use-c-14.patch
    # backport of facebookresearch/faiss#1666, can be dropped for ver>1.7.0
    - patches/0002-Add-missing-headers-in-faiss-gpu-CMakeLists.txt-1666.patch
    # update version-guard to build for compute_86, can be dropped for ver>1.7.0
    - patches/0003-update-util-guard-for-compute_86.patch
    # single commit from facebookresearch/faiss#1610
    - patches/0004-Add-missing-includes-for-std-min-std-max.patch
    # skip test that fails without GPU drivers on windows
    - patches/0005-skip-test-that-fails-without-GPU-drivers.patch  # [win]
    # backport of facebookresearch/faiss#1600, can be dropped for ver>1.7.0
    - patches/0006-make-AVX2-detection-platform-independent-1600.patch
    # backport of facebookresearch/faiss#1682, can be dropped for ver>1.7.0
    - patches/0007-make-setup.py-win-avx2-compatible-1682.patch
    # backport of facebookresearch/faiss#1683, can be dropped for ver>1.7.0
    - patches/0008-log-success-messages-and-errors-in-loader.py-1683.patch
    # backport of facebookresearch/faiss#1680, can be dropped for ver>1.7.0
    - patches/0009-add-msvc-compatible-AVX2-switch-in-CMakeLists.txt-16.patch
    # backport of facebookresearch/faiss#1681, can be dropped for ver>1.7.0
    - patches/0010-Win-AVX2-compat-1681.patch
    # backport of facebookresearch/faiss#1684, can be dropped for ver>1.7.0
    - patches/0011-Windows-portable-intrinsics-1684.patch
    # adapt header target directory for faiss_avx2
    - patches/0012-adapt-header-target-directory-to-outputname.patch

build:
  number: {{ number }}
  # GPU version for linux64 & win
  skip: true  # [osx and cuda_compiler_version != "None"]
  # DEBUG: temporarily disable win + cuda
  skip: true  # [win and cuda_compiler_version != "None"]

requirements:
  build:
    - {{ compiler('cxx') }}

outputs:
  # A meta-package to select CPU or GPU build for faiss.
  - name: faiss-proc
    version: 1.0.0
    build:
      string: {{ faiss_proc_type }}
    test:
      commands:
        - exit 0

  # build two separate C++ libs, one for generic x64, and one for AVX2
  {% for CF_FAISS_BUILD in ["avx2", "generic"] %}
  # order libfaiss last in loop due to conda/conda-build#4090; libfaiss-avx2
  # is only used for faiss and not important enough to work-around for this bug
  {% if CF_FAISS_BUILD == "generic" %}
  - name: libfaiss
  {% else %}
  - name: libfaiss-avx2
  {% endif %}
  {% set libext = "_avx2" if CF_FAISS_BUILD == "avx2" else "" %}
    # only one main build script build-lib.{bat|sh}, with the only difference
    # through CF_FAISS_BUILD={generic,avx2} that's set in the wrappers
    script: build-lib-{{ CF_FAISS_BUILD }}.sh   # [not win]
    script: build-lib-{{ CF_FAISS_BUILD }}.bat  # [win]
    build:
      string: "h{{ PKG_HASH }}_{{ number }}_{{ faiss_proc_type }}"                                                  # [cuda_compiler_version == "None"]
      string: "cuda{{ cuda_compiler_version|replace(".", "") }}h{{ PKG_HASH }}_{{ number }}_{{ faiss_proc_type }}"  # [cuda_compiler_version != "None"]
      run_exports:
        # faiss follows SemVer, so restrict packages built with libfaiss to use
        # at least the same version at runtime, but below the next major version.
        # (matches default arguments/behaviour of `pin_compatible`: min_pin='x.x.x.x.x.x', max_pin='x')
        - {{ pin_compatible('libfaiss{{ libext }}') }}
        # additionally, we need to ensure matching proc-type
        - libfaiss{{ libext }} =*=*_{{ faiss_proc_type }}
    requirements:
      build:
        - {{ compiler('cxx') }}
        - {{ compiler('cuda') }}  # [cuda_compiler_version != "None"]
        - cmake
        - libgomp                 # [linux]
        - llvm-openmp             # [osx]
      host:
        - libblas
        - liblapack
      run_constrained:
        - faiss-proc * {{ faiss_proc_type }}

    test:
      commands:
        # shared
        - test -f $PREFIX/lib/libfaiss{{ libext }}.so               # [linux]
        - test -f $PREFIX/lib/libfaiss{{ libext }}.dylib            # [osx]
        - if not exist %LIBRARY_BIN%\faiss{{ libext }}.dll exit 1   # [win]
        # On windows, faiss.lib is an "import library";
        # Deleting it breaks the faiss-builds
        - if not exist %LIBRARY_LIB%\faiss{{ libext }}.lib exit 1   # [win]

        # absence of static libraries
        - test ! -f $PREFIX/lib/libfaiss{{ libext }}.a              # [not win]

        # headers
        {% for each_header in headers %}
        - test -f $PREFIX/include/faiss{{ libext }}/{{ each_header }} || (echo "{{ each_header }} not found" && exit 1)  # [unix]
        - if not exist %LIBRARY_INC%\faiss{{ libext }}\{{ "\\".join(each_header.split("/")) }} exit 1                    # [win]
        {% endfor %}
  {% endfor %}

  - name: faiss
    script: build-pkg.sh          # [not win]
    script: build-pkg.bat         # [win]
    build:
      string: "py{{ CONDA_PY }}h{{ PKG_HASH }}_{{ number }}_{{ faiss_proc_type }}"                                                  # [cuda_compiler_version == "None"]
      string: "py{{ CONDA_PY }}cuda{{ cuda_compiler_version|replace(".", "") }}h{{ PKG_HASH }}_{{ number }}_{{ faiss_proc_type }}"  # [cuda_compiler_version != "None"]
    requirements:
      build:
        - {{ compiler('cxx') }}
        - {{ compiler('cuda') }}  # [cuda_compiler_version != "None"]
        - swig
        - cmake
        - libgomp                 # [linux]
        - llvm-openmp             # [osx]
      host:
        - python
        - pip
        - numpy
        - libfaiss ={{ version }}=*_{{ faiss_proc_type }}
        - libfaiss-avx2 ={{ version }}=*_{{ faiss_proc_type }}
        - libblas
        - liblapack
      run:
        - python
        - libfaiss ={{ version }}=*_{{ faiss_proc_type }}
        - libfaiss-avx2 ={{ version }}=*_{{ faiss_proc_type }}
        - {{ pin_compatible('numpy') }}
      run_constrained:
        - faiss-proc * {{ faiss_proc_type }}

    test:
      requires:
        # trying to test all blas-variants runs into conda/conda-build#3947
        # - blas * *{{ blas_impl }}
        # testing with MKL, as upstream considers this the most important
        - blas =*=mkl
        - scipy
        - pytest
      source_files:
        - tests/
      imports:
        - faiss
      commands:
        {% if not (osx or py36) %}
        # the linux & windows CI agents support AVX2 (OSX doesn't yet), so by default,
        # we expect faiss will load the library with AVX2-support, see
        # https://github.com/facebookresearch/faiss/blob/master/faiss/python/loader.py#L48-L60
        - python -c "from numpy.core._multiarray_umath import __cpu_features__; print(f'Testing version with AVX2-support - ' + str(__cpu_features__['AVX2']))"
        - pytest tests --log-file-level=INFO --log-file=log.txt
        # print logfile for completeness (sleep so log has time to print)
        - cat log.txt && sleep 2  # [not win]
        - type log.txt            # [win]
        # ensure that expected logger-messages from loader.py is present;
        # avoid final '\n', as well as the first 35 = len('INFO     faiss.loader:loader.py:51 ')
        - python -c "q = open('log.txt').readlines(); import sys; sys.exit(0 if 'Successfully loaded faiss with AVX2 support.' in [x[35:-1] for x in q] else 1)"
        # OTOH, we also want to test the packaged library without AVX2 support;
        # the advantage of the CPU feature detection in numpy is that it can be
        # deactivated, see documentation of NPY_DISABLE_CPU_FEATURES upstream;
        # however, the dict of CPU features is determined (and frozen) upon the
        # first import, so we cannot run both variants in a single run_test.py
        - export NPY_DISABLE_CPU_FEATURES=AVX2  # [not win]
        - set NPY_DISABLE_CPU_FEATURES=AVX2     # [win]
        {% endif %}
        - python -c "from numpy.core._multiarray_umath import __cpu_features__; print(f'Testing version with AVX2-support - ' + str(__cpu_features__['AVX2']))"
        # rerun test suite again without AVX2 support
        - pytest tests --log-file-level=INFO --log-file=log.txt
        - cat log.txt && sleep 2  # [not win]
        - type log.txt            # [win]
        # this should have run without AVX2; skip for py36 due to NPY_DISABLE_CPU_FEATURES not working
        - python -c "q = open('log.txt').readlines(); import sys; sys.exit(0 if 'Successfully loaded faiss.' in [x[35:-1] for x in q] else 1)"  # [py>36]

        # running the following test requires an actual GPU device, which is not available in CI
        # - pytest faiss/gpu/test/

  # for compatibility with (& ease of migration from) existing packages in the pytorch channel
  - name: faiss-cpu
    build:
      skip: true  # [cuda_compiler_version != "None"]
    requirements:
      run:
        - faiss ={{ version }}=*_cpu
    test:
      imports:
        - faiss

  - name: faiss-gpu
    build:
      skip: true  # [cuda_compiler_version == "None"]
    requirements:
      run:
        - faiss ={{ version }}=*_cuda
    test:
      imports:
        - faiss

about:
  home: https://github.com/facebookresearch/faiss
  license: MIT
  license_family: MIT
  license_file: LICENSE
  summary: 'A library for efficient similarity search and clustering of dense vectors.'

  description: |
    Faiss is a library for efficient similarity search and clustering of dense vectors.
    It contains algorithms that search in sets of vectors of any size, up to ones that
    possibly do not fit in RAM. It also contains supporting code for evaluation and
    parameter tuning. Faiss is written in C++ with complete wrappers for Python/numpy.
    Some of the most useful algorithms are implemented on the GPU. It is developed by
    [Facebook AI Research](https://research.fb.com/category/facebook-ai-research-fair/).

    For best performance, the maintainers of the package
    [recommend](https://github.com/conda-forge/staged-recipes/pull/11337#issuecomment-623718460)
    using the MKL implementation of blas/lapack. You can ensure that this is installed
    by adding "libblas =*=*mkl" to your dependencies.
  doc_url: https://rawgit.com/facebookresearch/faiss/master/docs/html/annotated.html
  dev_url: https://github.com/facebookresearch/faiss

extra:
  recipe-maintainers:
    - h-vetinari
