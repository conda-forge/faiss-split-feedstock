{% set version = "1.8.0" %}
# see github.com/conda-forge/conda-forge.github.io/issues/1059 for naming discussion
{% set faiss_proc_type = "cuda" if cuda_compiler_version != "None" else "cpu" %}

# headers for upstream-folders 'faiss/*.h', 'faiss/{impl,invlists,utils}/*.h',
# see https://github.com/facebookresearch/faiss/blob/v{{ version }}/faiss/CMakeLists.txt;
# gpu adds headers in 'faiss/gpu/*.h', 'faiss/gpu/{impl,utils}/*.(cu)?h'.
# generated by:
# ls faiss/ | grep -E "h$"
# ls faiss/gpu/ | grep -E "h$"
{% set headers = [
    'AutoTune.h', 'Clustering.h', 'IVFlib.h', 'Index.h', 'Index2Layer.h',
    'IndexAdditiveQuantizer.h', 'IndexAdditiveQuantizerFastScan.h', 'IndexBinary.h',
    'IndexBinaryFlat.h', 'IndexBinaryFromFloat.h', 'IndexBinaryHNSW.h', 'IndexBinaryHash.h',
    'IndexBinaryIVF.h', 'IndexFastScan.h', 'IndexFlat.h', 'IndexFlatCodes.h', 'IndexHNSW.h',
    'IndexIDMap.h', 'IndexIVF.h', 'IndexIVFAdditiveQuantizer.h', 'IndexIVFAdditiveQuantizerFastScan.h',
    'IndexIVFFastScan.h', 'IndexIVFFlat.h', 'IndexIVFIndependentQuantizer.h', 'IndexIVFPQ.h',
    'IndexIVFPQFastScan.h', 'IndexIVFPQR.h', 'IndexIVFSpectralHash.h', 'IndexLSH.h', 'IndexLattice.h',
    'IndexNNDescent.h', 'IndexNSG.h', 'IndexPQ.h', 'IndexPQFastScan.h', 'IndexPreTransform.h',
    'IndexRefine.h', 'IndexReplicas.h', 'IndexRowwiseMinMax.h', 'IndexScalarQuantizer.h',
    'IndexShards.h', 'IndexShardsIVF.h', 'MatrixStats.h', 'MetaIndexes.h', 'MetricType.h',
    'VectorTransform.h', 'clone_index.h', 'index_factory.h', 'index_io.h',
] + (cuda_compiler_version != "None") * [
    'gpu/GpuAutoTune.h', 'gpu/GpuCloner.h', 'gpu/GpuClonerOptions.h', 'gpu/GpuDistance.h',
    'gpu/GpuFaissAssert.h', 'gpu/GpuIcmEncoder.h', 'gpu/GpuIndex.h', 'gpu/GpuIndexBinaryFlat.h',
    'gpu/GpuIndexFlat.h', 'gpu/GpuIndexIVF.h', 'gpu/GpuIndexIVFFlat.h', 'gpu/GpuIndexIVFPQ.h',
    'gpu/GpuIndexIVFScalarQuantizer.h', 'gpu/GpuIndicesOptions.h', 'gpu/GpuResources.h',
    'gpu/StandardGpuResources.h',
] %}

package:
  name: faiss-split
  version: {{ version }}

source:
  url: https://github.com/facebookresearch/faiss/archive/v{{ version }}.tar.gz
  sha256: 56ece0a419d62eaa11e39022fa27c8ed6d5a9b9eb7416cc5a0fdbeab07ec2f0c
  patches:
    - patches/0001-adapt-header-target-directory-to-outputname.patch
    # patch for avoiding crash in GPU test suite on windows
    - patches/0002-skip-test_stress-for-GPU-on-windows.patch
    # enable building libfaiss_avx2 without libfaiss
    - patches/0003-enable-building-libfaiss_avx2-without-libfaiss.patch
    # increase tolerance for test that occasionally fails marginally
    - patches/0004-increase-tolerance-for-marginally-failing-test.patch
    # add /bigobj on windows to avoid: "fatal error C1128: number of sections exceeded object file format limit"
    - patches/0005-add-bigobj-to-swigfaiss-compile-options-on-windows.patch
    # patch out use of non-portable GCC SIMD extension
    - patches/0006-dont-use-GCC-extension-that-doesn-t-work-on-MSVC.patch
    # due to switch to ninja
    - patches/0007-no-more-Release-subfolder.patch
    # more fixes
    - patches/0008-fix-index-type-in-openmp-loop.patch
    - patches/0009-add-missing-headers.patch

build:
  number: 0

requirements:
  build:
    - {{ stdlib('c') }}
    - {{ compiler('cxx') }}
    - {{ compiler('cuda') }}  # [cuda_compiler_version != "None"]

outputs:
  # A meta-package to select CPU or GPU build for faiss.
  - name: faiss-proc
    version: 1.0.0
    build:
      string: {{ faiss_proc_type }}
    test:
      commands:
        - exit 0

  - name: libfaiss
    script: build-lib.sh    # [unix]
    script: build-lib.bat   # [win]
    build:
      string: "h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}_{{ faiss_proc_type }}"                                                  # [cuda_compiler_version == "None"]
      string: "cuda{{ cuda_compiler_version|replace(".", "") }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}_{{ faiss_proc_type }}"  # [cuda_compiler_version != "None"]
      run_exports:
        # faiss follows SemVer, so restrict packages built with libfaiss to use
        # at least the same version at runtime, but below the next major version.
        - libfaiss >={{ version }},<2
        # additionally, we need to ensure matching proc-type
        - libfaiss =*=*_{{ faiss_proc_type }}
    requirements:
      build:
        - {{ stdlib('c') }}
        - {{ compiler('cxx') }}
        - {{ compiler('cuda') }}  # [cuda_compiler_version != "None"]
        # necessary for conda-build to build the python bindings per version
        - python                  # [build_platform != target_platform]
        - cmake
        - ninja
        - libgomp                 # [linux]
        - llvm-openmp             # [osx]
      host:
        - libblas
        - liblapack
      run_constrained:
        - faiss-cpu ==9999999999  # [cuda_compiler_version != "None"]
        - faiss-gpu ==9999999999  # [cuda_compiler_version == "None"]
        - faiss-proc =*={{ faiss_proc_type }}

    test:
      commands:
        # shared
        - test -f $PREFIX/lib/libfaiss.so               # [linux]
        - test -f $PREFIX/lib/libfaiss.dylib            # [osx]
        - if not exist %LIBRARY_BIN%\faiss.dll exit 1   # [win]
        # On windows, faiss.lib is an "import library";
        # Deleting it breaks the faiss-builds
        - if not exist %LIBRARY_LIB%\faiss.lib exit 1   # [win]

        # absence of static libraries
        - test ! -f $PREFIX/lib/libfaiss.a              # [unix]

        # headers
        {% for each_header in headers %}
        - test -f $PREFIX/include/faiss/{{ each_header }} || (echo "{{ each_header }} not found" && exit 1)  # [unix]
        - if not exist %LIBRARY_INC%\faiss\{{ "\\".join(each_header.split("/")) }} exit 1                    # [win]
        {% endfor %}

  - name: faiss
    script: build-pkg.sh          # [not win]
    script: build-pkg.bat         # [win]
    build:
      string: "py{{ CONDA_PY }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}_{{ faiss_proc_type }}"                                                  # [cuda_compiler_version == "None"]
      string: "py{{ CONDA_PY }}cuda{{ cuda_compiler_version|replace(".", "") }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}_{{ faiss_proc_type }}"  # [cuda_compiler_version != "None"]
    requirements:
      build:
        - {{ stdlib('c') }}
        - {{ compiler('cxx') }}
        - {{ compiler('cuda') }}              # [cuda_compiler_version != "None"]
        - swig
        - cmake
        - ninja
        - libgomp                             # [linux]
        - llvm-openmp                         # [osx]
        - python                              # [build_platform != target_platform]
        - cross-python_{{ target_platform }}  # [build_platform != target_platform]
        - numpy                               # [build_platform != target_platform]
      host:
        - python
        - pip
        - numpy
        - libfaiss ={{ version }}=*_{{ faiss_proc_type }}
        - libblas
        - liblapack
      run:
        - python
        - packaging
        - libfaiss ={{ version }}=*_{{ faiss_proc_type }}
        - {{ pin_compatible('numpy') }}
      run_constrained:
        - faiss-cpu ==9999999999  # [cuda_compiler_version != "None"]
        - faiss-gpu ==9999999999  # [cuda_compiler_version == "None"]
        - faiss-proc =*={{ faiss_proc_type }}

    test:
      requires:
        # trying to test all blas-variants runs into conda/conda-build#3947
        # - libblas =*=*{{ blas_impl }}
        # testing with MKL on x86_64, as upstream considers this the most important
        - libblas =*=*mkl  # [x86_64]
        - scipy
        - pytest
      files:
        - test-pkg.bat
        - test-pkg.sh
      source_files:
        - tests/
      imports:
        - faiss
      commands:
        {% set skip = "_not_a_real_test" %}
        # flaky double encoding test that occasionally fails
        {% set skips = "test_RQ6x8" %}
        # TestComputeGT switches between CPU & GPU implementation depending on availability;
        # GPU device detection (on win) currently seems broken in CUDA, and segfaults the test suite
        {% set skips = skips + " or TestComputeGT" %}                                      # [win]
        # test relies on linux-isms
        {% set skips = skips + " or (test_contrib and test_checkpoint)" %}                 # [win]
        # marginal tolerance violation
        {% set skips = skips + " or (TestProductLocalSearchQuantizer and test_lut)" %}     # [osx]
        # two failing tests on on aarch (test_index_accuracy & test_index_accuracy2)
        {% set skips = skips + " or (test_residual_quantizer and test_index_accuracy)" %}  # [aarch64 or ppc64le]
        # the linux & windows CI agents support AVX2 (OSX doesn't yet), so by default,
        # we expect faiss will load the library with AVX2-support, see
        # https://github.com/facebookresearch/faiss/blob/v1.7.1/faiss/python/loader.py#L52-L66
        - export SKIPS="({{ skips }})" && ./test-pkg.sh  # [unix]
        - set "SKIPS=({{ skips }})"    && test-pkg.bat   # [win]

        # running the following test requires an actual GPU device, which is not available in CI
        # - pytest faiss/gpu/test/

  # for compatibility with (& ease of migration from) existing packages in the pytorch channel
  - name: faiss-cpu
    build:
      skip: true  # [cuda_compiler_version != "None"]
    requirements:
      run:
        - faiss ={{ version }}=*_cpu
    test:
      imports:
        - faiss

  - name: faiss-gpu
    build:
      skip: true  # [cuda_compiler_version == "None"]
    requirements:
      run:
        - faiss ={{ version }}=*_cuda
    test:
      imports:
        - faiss

about:
  home: https://github.com/facebookresearch/faiss
  license: MIT
  license_family: MIT
  license_file: LICENSE
  summary: 'A library for efficient similarity search and clustering of dense vectors.'

  description: |
    Faiss is a library for efficient similarity search and clustering of dense vectors.
    It contains algorithms that search in sets of vectors of any size, up to ones that
    possibly do not fit in RAM. It also contains supporting code for evaluation and
    parameter tuning. Faiss is written in C++ with complete wrappers for Python/numpy.
    Some of the most useful algorithms are implemented on the GPU. It is developed by
    [Facebook AI Research](https://research.fb.com/category/facebook-ai-research-fair/).

    For best performance, the maintainers of the package
    [recommend](https://github.com/conda-forge/staged-recipes/pull/11337#issuecomment-623718460)
    using the MKL implementation of blas/lapack. You can ensure that this is installed
    by adding "libblas =*=*mkl" to your dependencies.
  doc_url: https://rawgit.com/facebookresearch/faiss/master/docs/html/annotated.html
  dev_url: https://github.com/facebookresearch/faiss

extra:
  recipe-maintainers:
    - h-vetinari
